{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\n\nimport math\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models","metadata":{"execution":{"iopub.status.busy":"2022-04-30T03:00:05.084449Z","iopub.execute_input":"2022-04-30T03:00:05.084713Z","iopub.status.idle":"2022-04-30T03:00:05.093091Z","shell.execute_reply.started":"2022-04-30T03:00:05.084684Z","shell.execute_reply":"2022-04-30T03:00:05.092339Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# function to load, transform, normalise, and split dataset\ndef load_dataset(PATH):\n    # transform images to normalised tensors\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n    ])\n    # load and transform all images\n    dataset = torchvision.datasets.ImageFolder(\n        root=PATH,\n        transform=transform\n    )\n    # split dataset into training and validation\n    train_size = int(0.7 * len(dataset))\n    val_size = int(0.15 * len(dataset))\n    test_size = int(len(dataset) - train_size - val_size)\n\n    # use torch.utils.data.random_split for training/test split\n    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, num_workers=0, shuffle=True)\n    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, num_workers=0, shuffle=True)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, num_workers=0, shuffle=True)\n    \n    return train_loader, val_loader, test_loader\n\n\n\n\ndef display(img):\n    img = img / 2 + 0.5  # unnormalize images\n    npimg = img.numpy()\n    npimg = np.transpose(npimg, (1, 2, 0))\n    return npimg\n\n\n\n\n# function to train model\ndef train(model, device, train_loader, optimizer, epoch):\n    model.train()  # to set model to training mode\n    train_loss = 0\n    correct = 0\n    print(f'Epoch {epoch}:')\n    for batch_index, (image, label) in enumerate(train_loader):  # retrieve inputs\n        image, label = image.to(device), label.to(device)  # use GPU if able to\n\n        optimizer.zero_grad()  # reset optimiser parameters to 0\n\n        # forward\n        outputs = model(image)\n        loss = criterion(outputs, label)\n        train_loss += loss.item()  # track running total loss\n\n        loss.backward()  # backward\n        optimizer.step()  # optimize\n        \n        # print statistics every 10 batches\n        if batch_index % 10 == 9:\n            print('\\tTraining batch {} Loss: {:.6f}'.format(batch_index+1, loss.item()))\n\n        # print accuracy\n        _, pred = torch.max(outputs, dim=1)\n        correct += torch.sum(label == pred).item()\n\n    #  calculate the average loss and total accuracy per epoch\n    avg_loss = train_loss / (batch_index+1)\n    accuracy = 100.0 * correct / len(train_loader.dataset)\n    print('Training set: Average loss: {:.6f}, Accuracy: {}/{} ({:.3f}%)\\n'\n          .format(avg_loss, correct, len(train_loader.dataset), accuracy))\n    return avg_loss, accuracy\n\n\n\n\n# function to evaluate model on validation dataset\ndef validate(model, device, val_loader):\n    model.eval()  # to set model to evaluation mode (meaning no backpropagation)\n    val_loss = 0\n    correct = 0\n    with torch.no_grad():\n        batch_count = 0\n        for image, label in val_loader:\n            batch_count += 1\n            image, label = image.to(device), label.to(device) # uses GPU if possible\n            val_outputs = model(image)  # get predicted classes\n\n            # print loss\n            val_loss = criterion(val_outputs, label).item()\n\n            # print accuracy\n            _, pred = torch.max(val_outputs, dim=1)\n            correct += torch.sum(label==pred).item()\n\n        # calculate the average loss and total accuracy per epoch\n        avg_loss = val_loss / batch_count\n        accuracy = 100.0 * correct / len(val_loader.dataset)\n\n        print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.3f}%)\\n'\n              .format(avg_loss, correct, len(val_loader.dataset), accuracy))\n\n    # return average loss for the epoch\n    return avg_loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2022-04-30T03:00:05.108656Z","iopub.execute_input":"2022-04-30T03:00:05.108978Z","iopub.status.idle":"2022-04-30T03:00:05.128207Z","shell.execute_reply.started":"2022-04-30T03:00:05.108946Z","shell.execute_reply":"2022-04-30T03:00:05.127222Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Load dataset and set batch sizes\nDATA_PATH = '../input/roobansappani/HandGesture/images'\nclasses = sorted(os.listdir(DATA_PATH))\nprint(\"classes available: \", classes)\n\ntrain_loader, val_loader, test_loader = load_dataset(DATA_PATH)\nbatch_size = train_loader.batch_size\nprint(\"batch size: \", batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T03:00:05.132226Z","iopub.execute_input":"2022-04-30T03:00:05.132489Z","iopub.status.idle":"2022-04-30T03:00:05.181829Z","shell.execute_reply.started":"2022-04-30T03:00:05.132437Z","shell.execute_reply":"2022-04-30T03:00:05.181102Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# load random training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\n# view random image samples used for training\nfig, axis = plt.subplots(3, 5, figsize=(15, 10))\n\nfor i, ax in enumerate(axis.flat):\n    # remove ticks\n    ax.set_xticks([])\n    ax.set_yticks([])\n    with torch.no_grad():\n        image, label = images[i], labels[i]\n        ax.imshow(display(image)) # add image\n        ax.set(title = f\"{classes[label.item()]}\") # add label","metadata":{"execution":{"iopub.status.busy":"2022-04-30T03:00:05.183094Z","iopub.execute_input":"2022-04-30T03:00:05.183335Z","iopub.status.idle":"2022-04-30T03:00:06.265333Z","shell.execute_reply.started":"2022-04-30T03:00:05.183290Z","shell.execute_reply":"2022-04-30T03:00:06.264604Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# defining and initialising all cnn models used for implementation:\nclass BaseCNN(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 3)\n        self.conv2 = nn.Conv2d(6, 16, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(in_features=43616, out_features=120)\n        self.fc2 = nn.Linear(in_features=120, out_features=num_classes)\n\n    def forward(self, x):\n        # feature extractor\n        x = self.pool(F.relu(self.conv1(x)))\n        #print(x.shape)\n        x = self.pool(F.relu(self.conv2(x)))\n        # classifier\n        x = torch.flatten(x, 1)  # flatten layer\n        x = F.relu(self.fc1(x)) # fully connected layer\n        x = self.fc2(x) # fully connected layer\n        return x\n    \n    \nclass CNN1(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 3)\n        self.conv2 = nn.Conv2d(6, 6, 3)\n        self.conv3 = nn.Conv2d(6, 16, 3)\n        self.conv4 = nn.Conv2d(16, 16, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(in_features=41040, out_features=120)\n        self.fc2 = nn.Linear(in_features=120, out_features=num_classes)\n        self.dropout = nn.Dropout(0.25)\n\n    def forward(self, x):\n        # feature extractor\n        x = F.relu(self.conv1(x))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = F.relu(self.conv3(x))\n        x = self.pool(F.relu(self.conv4(x)))\n        # classifier\n        x = torch.flatten(x, 1)  # flatten layer\n        x = F.relu(self.fc1(x)) # fully connected layer\n        x = self.dropout(x)\n        x = self.fc2(x) # fully connected layer\n        return x\n    \n    \nclass CNN2(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 16, 3)\n        self.conv2 = nn.Conv2d(16, 16, 3)\n        self.conv3 = nn.Conv2d(16, 32, 3)\n        self.conv4 = nn.Conv2d(32, 32, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(in_features=82080, out_features=120)\n        self.fc2 = nn.Linear(in_features=120, out_features=num_classes)\n        self.dropout = nn.Dropout(0.25)\n\n    def forward(self, x):\n        # feature extractor\n        x = F.relu(self.conv1(x))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = F.relu(self.conv3(x))\n        x = self.pool(F.relu(self.conv4(x)))\n        # classifier\n        x = torch.flatten(x, 1)  # flatten layer\n        x = F.relu(self.fc1(x)) # fully connected layer\n        #x = self.dropout(x)\n        x = self.fc2(x) # fully connected layer\n        return x\n\n\nclass CNN4(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(in_features=23040, out_features=120)\n        self.fc2 = nn.Linear(in_features=120, out_features=num_classes)\n        self.dropout = nn.Dropout(0.25)\n        self.conv1_bn = nn.BatchNorm2d(16)\n        self.conv2_bn = nn.BatchNorm2d(32)\n        self.conv3_bn = nn.BatchNorm2d(64)\n        self.conv4_bn = nn.BatchNorm2d(128)\n        self.fc_bn = nn.BatchNorm1d(120)\n\n    def forward(self, x):\n        # feature extractor\n        x = self.conv1_bn(self.conv1(x))\n        x = self.pool(F.relu(x))\n        x = self.conv2_bn(self.conv2(x))\n        x = self.pool(F.relu(x))\n        x = self.conv3_bn(self.conv3(x))\n        x = self.pool(F.relu(x))\n        x = self.conv4_bn(self.conv4(x))\n        x = self.pool(F.relu(x))\n        # classifier\n        x = torch.flatten(x, 1)  # flatten layer\n        x = F.relu(self.fc_bn(self.fc1(x))) # fully connected layer\n        #x = self.dropout(x)\n        x = self.fc2(x) # fully connected layer\n        return x\n    \n\n# initialise model class\n#model = CNN4(num_classes=len(classes))\nmodel = models.vgg16(pretrained=True)\n\n\nfor param in model.parameters(): # freeze CNN to prevent updating weights for transfer learning\n    param.required_grad = False\n\nnum_ftrs = model.classifier[6].in_features\nmodel.classifier[6] = nn.Linear(num_ftrs, len(classes))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T03:00:06.266954Z","iopub.execute_input":"2022-04-30T03:00:06.267332Z","iopub.status.idle":"2022-04-30T03:00:07.395774Z","shell.execute_reply.started":"2022-04-30T03:00:06.267285Z","shell.execute_reply":"2022-04-30T03:00:07.394280Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# allocate model to device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # use GPU over CPU if available for faster training\nprint('device: ', device)\n\n# enable data parallelism if >1 GPU available\nif torch.cuda.device_count() > 1:\n    print('GPUs available: ', torch.cuda.device_count())\n    model = nn.DataParallel(model)\nelse:\n    print('Only 1 GPU available')\n\nmodel.to(device) # allocate model to device","metadata":{"execution":{"iopub.status.busy":"2022-04-30T03:00:07.396725Z","iopub.status.idle":"2022-04-30T03:00:07.397761Z","shell.execute_reply.started":"2022-04-30T03:00:07.397517Z","shell.execute_reply":"2022-04-30T03:00:07.397542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training and validation section:\ncriterion = nn.CrossEntropyLoss()  # specify loss criteria (softmax included)\noptimizer = optim.SGD(model.parameters(), lr=0.001)  # specify optimiser to adjust weights\n\n# arrays to track metrics\ntrack_epoch = []\ntraining_loss = []\nvalidation_loss = []\ntraining_accuracy = []\nvalidation_accuracy = []\n\n# running the model:\nnum_epochs = 10\nfor epoch in range(1, num_epochs+1):\n    train_loss, train_acc = train(model, device, train_loader, optimizer, epoch)\n    val_loss, val_acc = validate(model, device, val_loader)\n    track_epoch.append(epoch)\n    training_loss.append(train_loss)\n    validation_loss.append(val_loss)\n    training_accuracy.append(train_acc)\n    validation_accuracy.append(val_acc)\n\ntorch.save(model.state_dict(), 'vgg16.pth')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-30T03:00:07.399218Z","iopub.status.idle":"2022-04-30T03:00:07.399627Z","shell.execute_reply.started":"2022-04-30T03:00:07.399408Z","shell.execute_reply":"2022-04-30T03:00:07.399430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create epoch-loss graph\nplt.figure(figsize=(15, 15))\nplt.plot(track_epoch, training_loss, marker='o')\nplt.plot(track_epoch, validation_loss, marker='o')\nepoch_int = range(math.floor(min(track_epoch)), math.ceil(max(track_epoch)) + 1)\nplt.xticks(epoch_int, fontsize=20)\nplt.yticks(fontsize=32)\nplt.xlabel('Epoch', fontsize=32)\nplt.ylabel('Loss', fontsize=32)\nplt.legend(['Training', 'Validation'], loc='upper right', fontsize=32)\nplt.title('VGG16 Loss', fontsize=40)\nplt.show()\n\n# create epoch-accuracy graph\nplt.figure(figsize=(15, 15))\nplt.plot(track_epoch, training_accuracy, marker='o')\nplt.plot(track_epoch, validation_accuracy, marker='o')\nepoch_int = range(math.floor(min(track_epoch)), math.ceil(max(track_epoch)) + 1)\nplt.xticks(epoch_int, fontsize=20)\nplt.yticks(fontsize=32)\nplt.xlabel('Epoch', fontsize=32)\nplt.ylabel('Accuracy', fontsize=32)\nplt.legend(['Training', 'Validation'], loc='upper right', fontsize=32)\nplt.title('VGG16 Accuracy', fontsize=40)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T03:00:07.400793Z","iopub.status.idle":"2022-04-30T03:00:07.401506Z","shell.execute_reply.started":"2022-04-30T03:00:07.401312Z","shell.execute_reply":"2022-04-30T03:00:07.401337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate final model on test set\nmodel.load_state_dict(torch.load('../input/final/vgg16 (1).pth'), strict=False) # load pretrained final model\n\n# defining labels and predictions on test dataset for the confusion matrix\ntruelabels = []\npredictions = []\nmodel.eval()\ncorrect = 0\nbatch_count = 0\n\nprint(\"Getting predictions from test set...\")\nfor image, label in test_loader:\n    batch_count += 1\n    image, label = image.to(device), label.to(device) # uses GPU if possible\n    test_output = model(image)  # get predicted classes\n    \n    # to print accuracy\n    _, pred = torch.max(test_output, dim=1)\n    correct += torch.sum(label==pred).item()\n    \n    # track results for the graph\n    for label in label.cpu().data.numpy():\n        truelabels.append(label)\n    for prediction in model(image).cpu().data.numpy().argmax(1):\n        predictions.append(prediction)\n\n# calculate total accuracy\naccuracy = 100.0 * correct / len(test_loader.dataset)\nprint('Test set accuracy: {}/{} ({:.3f}%)\\n'.format(correct, len(test_loader.dataset), accuracy))\n\n\n# plot a confusion matrix\ncm = confusion_matrix(truelabels, predictions)\ntick_marks = np.arange(len(classes))\ndf_cm = pd.DataFrame(cm, index = classes, columns = classes)\nplt.figure(figsize = (15,15))\nsns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.xlabel(\"Predicted Label\", fontsize = 32)\nplt.ylabel(\"True Label\", fontsize = 32)\nplt.title('Bad Model Confusion Matrix', fontsize=40)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T03:00:15.791843Z","iopub.execute_input":"2022-04-30T03:00:15.792349Z","iopub.status.idle":"2022-04-30T03:00:24.259419Z","shell.execute_reply.started":"2022-04-30T03:00:15.792307Z","shell.execute_reply":"2022-04-30T03:00:24.258778Z"},"trusted":true},"execution_count":14,"outputs":[]}]}